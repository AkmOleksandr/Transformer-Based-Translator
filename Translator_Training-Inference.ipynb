{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "t1G2ZjccLb9p"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install datasets\n",
        "!pip install tokenizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INs7DQmLLi8q",
        "outputId": "253a23de-b2f1-4303-c8f4-ac0c2f7fdc8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'Transformer-Based-Translator'...\n",
            "remote: Enumerating objects: 183, done.\u001b[K\n",
            "remote: Counting objects: 100% (60/60), done.\u001b[K\n",
            "remote: Compressing objects: 100% (47/47), done.\u001b[K\n",
            "remote: Total 183 (delta 42), reused 13 (delta 13), pack-reused 123\u001b[K\n",
            "Receiving objects: 100% (183/183), 1001.93 KiB | 2.97 MiB/s, done.\n",
            "Resolving deltas: 100% (100/100), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/AkmOleksandr/Transformer-Based-Translator.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fsMKuSJFLq1E"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%cd /content/Transformer-Based-Translator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oOinJuepuE6",
        "outputId": "d41e8fa5-de85-4074-a91e-38df300a9d5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current Directory: /content/Transformer-Based-Translator\n",
            "Directory Contents: ['eng-ukr-dataset', 'dataset.py', '.git', 'model.py', 'train.py', 'config.py', 'change_format.py', '.gitignore', 'translate.py']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Print current directory\n",
        "print(\"Current Directory:\", os.getcwd())\n",
        "\n",
        "# Print directory contents\n",
        "print(\"Directory Contents:\", os.listdir())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "MzHei5H4Lgna"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Tmgw69SyLvqg"
      },
      "outputs": [],
      "source": [
        "!mkdir -p /content/drive/MyDrive/MyModels/Translator/weights\n",
        "!mkdir -p /content/drive/MyDrive/MyModels/Translator/vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXCRxXXkL-81",
        "outputId": "af368592-f345-440a-8915-e73246029a74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preloading model ../drive/MyDrive/MyModels/Translator/weights/tmodel_15.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 16: 100%|██████████| 1477/1477 [08:41<00:00,  2.83it/s, loss=1.642]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: We like chocolate milk.\n",
            "    TARGET: Ми полюбляємо шоколадне молоко.\n",
            " PREDICTED: Ми любимо шоколадне молоко .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: That isn't love.\n",
            "    TARGET: Це не кохання.\n",
            " PREDICTED: Це не кохання .\n",
            "--------------------------------------------------------------------------------\n",
            "Saving model to: ../drive/MyDrive/MyModels/Translator/weights/tmodel_16.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 17: 100%|██████████| 1477/1477 [08:41<00:00,  2.83it/s, loss=1.729]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: The cave-man spoke Toki Pona.\n",
            "    TARGET: Печерна людина розмовляла на такі-пона.\n",
            " PREDICTED: людина розмовляла на такі - .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: He was accompanied by his wife.\n",
            "    TARGET: Його супроводжувала дружина.\n",
            " PREDICTED: Його дружина .\n",
            "--------------------------------------------------------------------------------\n",
            "Saving model to: ../drive/MyDrive/MyModels/Translator/weights/tmodel_17.pt\n"
          ]
        }
      ],
      "source": [
        "from config import get_config\n",
        "\n",
        "cfg = get_config()\n",
        "\n",
        "cfg['model_folder'] = '..//drive/MyDrive/MyModels/Translator/weights'\n",
        "cfg['tokenizer_file'] = '..//drive/MyDrive/MyModels/Translator/vocab/tokenizer_{0}.json'\n",
        "cfg['batch_size'] = 8\n",
        "cfg['num_epochs'] = 18\n",
        "\n",
        "from train import train_model\n",
        "\n",
        "train_model(cfg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "oBrO9iGWTG4y"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from config import latest_weights_file_path\n",
        "from train import get_model, get_ds, run_validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "tpw47D1udljP"
      },
      "outputs": [],
      "source": [
        "from translate import get_translation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ds5SHLP4Tflz",
        "outputId": "1b75b2c9-eaa7-4abb-a216-fadf26a5fb5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "../drive/MyDrive/MyModels/Translator/weights/tmodel_17.pt\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Define the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "train_dataloader, val_dataloader, tokenizer_src, tokenizer_tgt = get_ds(cfg)\n",
        "model = get_model(cfg, tokenizer_src.get_vocab_size(), tokenizer_tgt.get_vocab_size()).to(device)\n",
        "\n",
        "# Load the pretrained weights\n",
        "model_filename = latest_weights_file_path(cfg)\n",
        "print(model_filename)\n",
        "state = torch.load(model_filename)\n",
        "model.load_state_dict(state['model_state_dict'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "AwqPfVe_TnDf"
      },
      "outputs": [],
      "source": [
        "input_text = [\"We will eat\", \"They like to watch TV\", \"I like singing\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "685rZ7gsTzU_",
        "outputId": "49e89450-7e48-44b2-b35e-73b6afd7974c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "    SOURCE: We will eat\n",
            " PREDICTED: Ми будемо їсти  .\n",
            "Using device: cuda\n",
            "    SOURCE: They like to watch TV\n",
            " PREDICTED: Вони хочуть люблять люблять дивитися телевізор дивитися телевізор\n",
            "Using device: cuda\n",
            "    SOURCE: I like singing\n",
            " PREDICTED: Мені подобається співати я люблю співати .\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(input_text)):\n",
        "  output_text = get_translation(cfg, input_text[i])\n",
        "  print(output_text)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
